This file contains High-level overview of the binding architecture.


TOC:

.Net versions

Unity

Mono

File locations, development

File locations, distribution

The release batch files

How we handle 32,64,debug,release issues

runtime code files (c++ dll,C# assembly, 32bit 64 bit etc)

Class structure,How we wrap c++ classes

How the examples archive is set up

How things are organized on github

Typed binding discussion





.Net versions
-----------------------------------

Binding projects :
.net35 (used in unity example)
.net40
.net45 (default)
Unit-test version :
.net45 (default) (can be used with NUnit)
Unit-test commandline projects
.net35
.net40
.net45

The binding exists in several versions, .net35 .net40 and .net45

All the different versions are located in the same solution, tightDbCSharp.sln

We maintain a project that uses the latest version, this project is called TightDbCSharp 
This project is currently set to build to .net45 but will in the future (when we switch to VS2013)
be set to build to .net451 - so TightDbCSharp is always the newest .net version, and it is the
project that "owns" the source files - source files are added directly to this project, not "as link".
Delvelopment is done primarily using this project.
Accompanying this project is a project called TightDbCSharpTest - this project follows the version of TightDbCSharp,
and is a Nunit unit-test project, useful for testing with Nunit test-runners.
As NUnit integration with VS2012 is a bit spotty, and as it is practical to be able to execute tests as
commandline programs, we have create a very small commandline program that uses NUnitLite to enable us to
run the unit tests directly from within a program. The unit test commandline project is simply called TEST, and it
includes the files from TightDbCSharpTest as links.

So to recap the default version of the binding :

TightDbCSharp - project that bulds the assembly that is tightdb, that is used by our customers
Test - commandline project that uses the binding, and implements a program that runs all our unit tests.
TightDbCSharpTest - assembly that uses the binding, containing a unit test module, to be used in NUnit or any other Nunit compatible unit test runner

Note that only the dll resulting from TightDbCSharp is being distributed, the two other projects are for internal use

TightDbCSHarpTest contains all our unit tests
Test simply links to the files in TightDbCSharp, and using NUnitLite, it compiles an executable that is a self-contained test runner.

Now, to support building different versions of .net and also building executables that run unit tests without any additional installs, we have:

Used to Build Binding versions :
TightDbCSharp_NET35  -   a project set to build to .net35. The project links its source files to the files in TightDbCSharp
TightDbCSharp_NET40  -   a project set to build to .net40. The project links its source files to the files in TightDbCSharp
TightDbCSharp - a project set to build to .net45. The project owns the source files, they are all located in this project. It is always using the newest .net
so when we get VS2013 we will update this project to .net451 and create a new TightDbCSharp_NET45 and have that project link to files in TightDbCSharp

Used to Build test-programs that test the binding versions above
Test_NET35 - a .net35 program that uses the TightDbCSharp_NET35 assembly and NUnitLite and runs all the unit tests from the TightDbCSharpTest source files, which are added as link
Test_NET40 - a .net40 program that uses the TightDbCSharp_NET40 assembly and NUnitLite and runs all the unit tests from the TightDbCSharpTest source files, which are added as link

Test - a .net45 program that uses the TightDbCSharp_NET45 assembly and NUnitLite and runs all the unit tests from the TightDbCSharpTest source files, which are added as link. Test follows
the newest .net version, when we go to vs2013 and .net451 Test will follow along (changing the target framework) and we will then create a project called TEST_NET45 , set it to .net45 and have it
link to the source files in TightDbCSharpTest as we do with Test_NET40 and Test_Net35



Unity
--------------

Unity runs in a crippled version of mono, where they have removed a lot of the standard libraries to try to make unity games not use so much disk space for the distribution files,
and so much memory too, I guess.
The mono version they used when I created the UnityExample was not able to run .net40 or .net45 so I used the .net35 binding in unity to get a connection.
The .net35 binding is executed fine within unity, in the examples dir, You will find a textfile that explains how to set up a new unity project that uses tightdb 
(it is a walkthrough of how to implement the tutorial example inside unity).
I have not had luck with getting the .net35 commandline unit test to run inside unity - the NUnitLite code does not discover the tests, so no tests are run. This is probably due to unity having
removed some API's that NunitLite depends on - I have not researched this a lot, a working tutorial was good enough for what we needed at that time.
Some unity supported platforms on windows do not support P/Invoke (do not support calling c++ program dll's AT ALL), these platforms would have to be supported by us, using a core developed
specially for that purpose - or perhaps using an intermediary that can be called from these non-p/invoke .net versions, and when the intermediary then is able to call c++ programs.
c++/cli is an option (strictly windows only, but an option) if we want to attack that market. Would take some time to get it right, though.
Other unity platforms run on hardware and OS'es that core has not been ported to yet. We would have to do that first, of course.



Mono
--------------
I have tested that mono can execute our .net assemblies, and that works fine. The unit test commandline programs will detect mono and report they are running under mono.

I have also tried to build our assemblies with xamarin (the mono C# compiler) just to see what happened, and that also worked fine, but building with xamarin is not part
of the development procedures, as mono is supposed to be able to run .net assemblies. - we don't need to (for the moment) maintain two seperate lines of code.

Although mono (at the time of writing) do not have a 64 bit version for windows, there is shipped one with unity, if you build a 64 bit unity game, our binding reports running
in 64 bit with large IntPtr size. So indirectly we can verify that mono runs our 64 bit assembly fine, by doing the testing inside unity. Alternatively we can just wait for mono
to release a 64 bit version of mono for windows.

We have had a problem with the latest release of mono, where they have crippled exception handling such that core cannot use execptions itself - core cannot throw an exception,
and we cannot catch it in the c++ program that is the binding dll. I have filed at bug with mono describing this problem, https://bugzilla.xamarin.com/show_bug.cgi?id=14989#c1  but
nothing have really happened. I would expect them to fix this issue by themselves, when they discover that mono on windows is severely broken. Alternatively we could file a bug
report where a well known system fails on mono, that might attract some attention. All we have to do is find something that is coded with c++, built with visual studio, and that
relies on exceptions being thrown and caught in the c++ code.

I have not yet had our c++ dll built on linux, so have not tried to run our assembly on linux (as we have no core dll to call) - We might need some adjustments before things work there.




File Locations, development
---------------------------

\
contains some documentation, the solution file, release_all.cmd, the 7z compressor (used to make a zip file)
native\  
contains files used to build core as a dll, with flattened interface "C" methods for our assembly to call
Test\ 
contains the Test project (current development version commandline interface unit tests runner)
Test_NET35\ 
Test project set up to create a .net35 executable (same tests as TEST use, but different settings)
Test_NET40\ 
Test project set up to create a .net35 executable (same tests as TEST use, but different settings)
TightDbCSharp\ 
Project that produces the binding assembly. Contains all the source needed for producing the binding
TightDbCSharp_NET35\
project that produces the .net35 version of the binding. .net35 project setup, but source is links to TightDbCSharp
TightDbCSharp_NET40\
project that produces the .net40 version of the binding. .net40 project setup, but source is links to TightDbCSharp
TightDbCSharpTest\
NUnit assembly that can be used with a NUnit test-runner. Holds all our unit-test sourcecode files, these files are 
linked to, by our Test projects
Examples\
Contains click-and-run examples for users to investigate. These examples are all fully self contained, 
and will run with no installation at all (given the user already have installed windows .net and c++ runtime support)
They do not even inter-depend on anything, so each subdirectory below examples is fully self contained.
Examples\DynamicTable
Showcasing a lot of different methods in the Table class
Examples\Experimental
Showcasing some alternative code syntaxes, and some experimental designs
Examples\PerformanceTest
A commandline program that tests performance. The output from the insert test is used as input in the 
google drive shared spreadsheet we have, that tries to measure how much memory we use, compared to C# arrays
Examples\TutorialSolution
The tutorial in a project of its own.
Examples\UnityExample
A readme file and the files otherwise needed to create a tutorial example inside unity.
The user must follow the readme file instructions to build a new unity game, that can display 
debug information from the tightdb binding, and run (a slighlty modified version of) the tutorial



File Locations, distribution
---------------------------

release\
When You have run the release_all script, this directory will contain all the release files
release\release\
This directory contain an archive with the release as a zipfile.
release\files\
This directory contain an uncompressed version of the release
release\files\examples\
self contained examples for the user to run and experiment with
release\files\tighDB\
Binding assemblies and dll's for varios .net versions
release\files\tightDB\NET35\
.net 35 version of binding and dll's - these are the files that are needed when You use tightdb with .net35
release\files\tightDB\NET40\
.net 40 version of binding and dll's - these are the files that are needed when You use tightdb with .net40
release\files\tightDB\NET45\
.net 45 version of binding and dll's - these are the files that are needed when You use tightdb with .net45
doc\
Directory with stuff that is used by the TightDb web documentation system





The release batch files
-----------------------
At the same place You have tightdbCSharp.sln, You also have release_all.cmd
When You have built TightDbCSharp following the build instructions, this cmd file
will do the copying of files needed to assemble a distribution in the release
directory. The end result is the zip file we put on the website for download.
Release_all.cmd relies on Release.cmd, and 
native\tightdb_c_cs\tightdb_c_cs2012\release.cmd 
The last one will copy the c++ files from their build destinations to a release
directory, so that we have the c++ dll's organized there as a release.
the first one will copy the c++ files and the C# files and the example files,
into release\files and create a release zip archive in release\release
Remember that to make a release You have to have already built everything,
all the way from core LIB files, to core dll's, to C# assemblies. See readme.MD for
how to do that correctly.




How we handle 32,64,debug,release issues
----------------------------------------


.net is a little bit special when it comes to 32 and 64 bit

A user can specify a project to build for 64 bit. That will mean that the project will
only run on a 64 bit .net VM, on a 64 bit Operating System

A user can specify a project to build for 32 bit. That will mean that the project will
only run on a 32 bit .net VM, on a 64 bit or 32 bit Operating System (on windws, 64 bit OS 
and 32bit .net VM is done by using WOW).

The two above, could use compile time directives to enable and disable code that is dependent
on the size of a pointer, or other stuff that differs from 32 to 64 bit (like what DLL file should we call
when interop p/invoke calls are done from C# to c++)

However, there is this third kind of C# project - AnyCpu - and such a project will not know
at compile time what bitness it will be running with. The bitness is decided by the VM that the 
program is eventually started up within, so we cannot use compiler directives.

For all the three above, we must remember to call debug dll's when in debug mode, and release dll's when
in release mode. HOWEVER the binding itself is only shipped in release mode (users can still build their own
programs in debug mode - but they should not have to run our binding code in debug mode). Therefore the user
only needs to ship the c++ dll in release mode. Binding debug and c++ dll debug are used by us.

tightDbC# will decide at runtime wether to call 64 bit or 32 bit DLL c++ functions, this is done
by having a boolean Is64Bit that is used to determine if we should call a function that links to the 64 bit
c++ DLL, or one that links to the 32 bit c++ DLL.  In C# interop the DLL filename has to be known at compile time,
so we have to decide what filename to use at runtime by calling one of two possible methods.

A typical call to c++ will look like this (I added in the stuff it depends on)


//const definition that differs between debug and release builds
#if (DEBUG)
        private const string Buildmode = "d";
        private const string BuildName = "Debug";
#else
        private const string Buildmode = "r";
        private const string BuildName = "Release";
#endif


//const strings for 64bit file and 32bit file
        private const String L64 = "tightdb_c_cs201264" + Buildmode;
        private const String L32 = "tightdb_c_cs201232" + Buildmode;



        //a call to the c++ dll with flattened core calls
        //tightdb_c_cs_API size_t tightdb_c_csGetVersion(void)
        [DllImport(L64, EntryPoint = "tightdb_c_cs_getver", CallingConvention = CallingConvention.Cdecl)]
        private static extern IntPtr tightdb_c_cs_DllVer64();

        [DllImport(L32, EntryPoint = "tightdb_c_cs_getver", CallingConvention = CallingConvention.Cdecl)]
        private static extern IntPtr tightdb_c_cs_DllVer32();

        private static long CppDllVersion()
        {
            if (Is64Bit)
                return (long) tightdb_c_cs_DllVer64();
            return (long) tightdb_c_cs_DllVer32();
        }



runtime code files
------------------

(see paragraph above)
This means that the user should distribute the following files always when distributing a c# program using tightdb :

TightDbCSharp.dll  - the binding assembly
Tightdb_c_cs201232r.dll - the 32 bit c++ dll
Tightdb_c_cs201264r.dll - the 64 bit c++ dll
-
TightDbCSharp.pdb  - optional to include (debugging info etc.)

These 3 files should be located in the same directory, TightDbCSharp.dll will first try to load the dll files where it itself is located, then
use .net standard strategy fro locating unmanaged dll files (using path etc.)

For debugging purposes, the ToolBox.cs class have a few methods that will return a stringlist with debug information :

Toolbox.ShowVersionTest();
results in this on the console :

---OS Info---
OS Version                  : 6.1.7601.65536
OS Platform                 : Win32NT
64 Bit OS                   : Yes
64 Bit process              : True
---OS Info---

---CLR Info---
Pointer Size                : 8
Process Running as          : 64bit
Running on mono             : False
Common Language Runtime     : 4.0.30319.18408
---CLR Info---

---C# binding (TightDbCSharp.dll) Info---
Built as PeKind           : ILOnly
Built as ImageFileMachine : I386
Debug Or Release          : Release
Compiled With Mono        : No
Built for .net version    : V4.5
---C# binding (TightDbCSharp.dll) Info---

---C++ DLL Info---
Assembly running right now :
E:\Wincoder\Develope\tightdb_csharp\examples\PerformanceTest\bin\AnyCpu\TightDbC
Sharp.dll
Current Directory :
E:\Wincoder\Develope\tightdb_csharp\examples\PerformanceTest\bin\AnyCpu

Now Loading tightdb_c_cs201264r - expecting it to be a 64bit dll


DLL File Actually Loaded :E:\Wincoder\Develope\tightdb_csharp\examples\Performan
ceTest\bin\AnyCpu\tightdb_c_cs201264r.DLL

C#  DLL        build number 201310181348
C++ DLL        build number 201310252
---C++ DLL Info---



class structure,How we wrap c++ classes
---------------------------------------


Handle Classes:


Please consult the HandleClasses.classdiagram found in ModelingProject1 in the solution

Handles used to call the c++ part of the bindings are stored not as IntPtr, but as objects derived from CriticalHandle, 
see concurrencynotes.txt for details about why we have done that.

TightDbHandle inherits from CriticalHandle, and introduces a property (Root) that points to the TightDbHandle that is the
root as seen from a concurrency perspective, related to this object. For instance, a SharedGroup is root for all the
tables, tableviews, queries and subtables that are taken out from this tableview. A freestanding Table is root for all the subtables,
tableviews and queries taken out from that table, and its tableviews. A freestanding Group is root for all the tables taken
out from that group, all the objects taken out from those tables etc. The rule is, if it is not okay to concurrently access
a group of objects, then they belong to the same root. (it is okay to concurrenlty access several SharedGroup objects, and
it is also okay to concurrenlty access several freestanding tables).
So - To simplify, think of the root as the SharedGroupHandle, and the objects that have a root reference to that SharedGroupHandle
as children of that root.

When a TightDbHandle class is finalized,we cannot call unbind, as this finalization could happen concurrently with user-thread
operations on the TightDbHandle's root, or one of the TightDbHandle's root's children. Therefore Unbind has been coded to do this:

if root is null : 
We are the root and as unbind is being called, we are either being disposed or finalized. 
If we are being disposed, we are in the user thread and we cannot collide with any other user thread, as we are the only
user thread in the root and its children by definition. As the TightDbHandle architecture guarentees that all children in
a non-disposed root will never call unbind on a finalizer thread, we cannot collide with finalizer thread code. Therefore it
is safe to unbind ourselves. Before we unbind ourselves, we unbind any children present in the unbind list.
If we are being finalized, we know there is no more user threads accessing our root. Proof by contradiction - our children all 
have a reference to us. Any user thread in a child would have kept us alive, so we could never be finalized. If another user
thread have a reference to us, we also could not have been finalized. So the fact that we are being finalized is a guarentee that
no user threads are accessing us or one of our children. The only access to root and children can be via finalizers.
Therefore, we know for sure that no user threads can be accessing us, if we are a root.

At unbind, A root will mark it self as _NoMoreUserThreads=true, then unbind its unbind list, then unbind itself, and while doing so, 
taking a lock on itself to enable serialization with any finalizers in any children. This behavior is safe due to the details described 
in the paragraph before.

if root is not null : 
We are a child, we are being called from child.dispose or from a finalizer, our root could be already disposed or it could be still alive.
In any case, we just call root.RequestUnbind(this) and let the root figure out if we should be unbound at once, or put on its unbind list.
The root will inspect its own status, if NoMoreUserThreads=true the root will unbind us at once (using lock to ensure serialization with
other finalizers). If NoMoreUserThreads is false, the root will put us into its unbind list (using lock to ensure serialization of the list
with other user threads and finalizers), and it will then later unbind us either when it itself finalizes, 
or when it is called next time from a user thread (during object creation of a new child for that root)

The above logic is all coded into TightDbHandle. The binding does not use TightDbHandle directly, but the various handles inherit from
TightDbHandle and implement ReleaseHandle, which is the method that should call into c++ and do the actual unbinding of the specific class.

There is a special class, called TightDbHandleOptionalUnbind - this class is instantiated with a boolean, specifying if ReleaseHandle should
in fact be called or not. GroupHandle and SpecHandle inherit from TightDbHandleOptionalUnbind, and thus have the feature that they can be either
owned by their root (will be finalized/unbound/released when not used any more), or not owned by their root(will not be finalized/unbound/released
when not used anymore). 
GroupHandle:Free standing groups must be deleted, but groups from inside SharedGroup should not be deleted.
SpecHandle:A Table's Spec should not be unbound, but a subspec should be.

The above explains how TightDbHandle is used for handling the core requirenment that any root object and its children can only be called serially.

Please consult concurrenct.txt for explanations on how we handle the following :
-Handle leaks
-Handle recycling


Toolbox class:


This class contains methods that are not really part of core, but helper functions used in diagnostics, such as a method that
reports what binding dll we have linked to, and what bitness we are running, what version we are, and other system info.
the Toolbox class is specific for the C# binding.


Handled class:


All TightDb wrapper classes in the C# binding inherit from Handled. Handled implements very few things, amongst those a TightDBHandle
reference, and some dispose logic, calling the handle's dispose method. The Handled class, and its descendants does NOT implement 
finalize, so these objects are garbage collected fast, as soon as they are not used anymore.
The following classes inherit from Handled :
SharedGroup
Group
TableOrView (abstract class, implementing all things common to Table and TableView such as validation and C# specific high level stuff)
Table
TableView
Query

In general, the classes will use methods in their handles to instantiate new c++ instances, and methods in themselves to operate 
on these wrapped instances. The handles alone are responsible for unbinding. The Query class contains all core operations that
can be done on a Query, same with Table, TableView etc. The C# classes basically validates input, then call on to core with validated
parametres.


Row class:


Table and TableOrView implement enumeration, and if You do a foreach on a Table (or TableView or Query) You will get Row objects, where 
each Row object hold the RowIndex of the underlying table, as well as a reference to that table. Row also has all the methods that
could be naturally called on a table row, such as GetInteger(ColumnIndex) etc. etc. TableRow will call back to its underlying table
to have these methods executed. The Row class can itself be enumerated and a Foreach(RowCell) will return cell objects that can be
called to get/set the value of that field. This implementation enables LinQ to work with tightdb Tables out of the box.





How the examples archive is set up
----------------------------------

The examples archive contain a readme file and a number of directories, each directory containing a fully self-containing and functional C# solution,
(.net45), that includes a project, that can be run with no installation. The project contains the 3 tightdb files needed to run a program with the 
tightdb C# binding, and the project is set up to use these files. 
Therefore people can simply unpack the examples archive, and then experiment with the examples, without having to do any kind of install or setup.
The examples directory will only work if You have installed Visual Studio 2012, and if you have installed c++ runtime v110 (is usually installed with
VS).
The individual projects have been set up to reference the tightdb C# binding file, which is included in the main project directories. The c++ dil's
have been included in the projects as assets, and they are marked as copy so that the built version of the project will have the two files included
at the .exe file and therfore they can be called from the C# program.

The unity project is a bit special as it is set up for unity, it contains of a readme file, and some support files, that guide You through creating
a project file in unity. The unity project is therefore not "run out of the box" as the other projects - it is a tutorial that guides You through
creating a unity game that uses tightdb.





How things are organized on github
----------------------------------
The main repository is at https://github.com/Tightdb/tightdb_csharp
This repository is usually forked by developers, and then they further create a local copy of the fork.
Use pull requests to get the main repo updated from Your fork.
Github does not store the release directories, only the source needed to produce releases.
The Gitignore file contains a lot of temporary and build files that should not be comitted to github.
Documentation using the tightdb documentation system is very sparse, only the tutorial have been done.



Typed binding discussion
------------------------

C# have something called T4 templates that might be useful to some degree to make some classes where the code is generated from the binding, this is one way
to do a typed interface - first the user creates a Table class with structure, then somehow gets that class to emit the sourcecode to a typed class that can
access the untyped table. It will take a little time to figure if this can become elegant. T4 tamplates is also supported in some mono development tools, I have
not used it, and have not looked into how compatible it is across platforms. But if we want to do something resembling templates and autogenerated code, T4 is
an option.

As I see it, a user of the binding would typically already have a class, say  customer, that contains many fields and methods. The user would like to store the
customer class in tightdb, but usually only some of the fields need to be stored - other fields might only make sense at runtime. The user is probably lazy and
would rather not have to write code that moves data from customer objects to tightdb.
We might be able to concieve some kind of annotation system such that we could for instance do CustomerTable.Store(ACustomer)  then CustomerTable would in runtime
inspect the customer object for fields that it shoudl store, and then store it. The interesting part is that ACustomer is a class that the user already have coded
in his existing system, but still we provide a safe way of storing to a Table, and reading from it.  We migt also get away with CustomerTable.Store(ACustomer.Name),
then we would have to inspect Acustomer to see if the Name field is annotated to be stored in the customertable, then store it.
The above solution will rely on inspection etc. and might not be super fast, compared to something hardcoded.

With T4 we might be able to perhaps combine annotations and T4 to have new customer classes generated that read/write to a compatible table automatically and fast,
but the user will then have his existing customer class, and our fast class, and still have to move data back and forth between the two classes.

no matter what solution we decide to make, we can always make a "createTypedClass" method call that returns a string with the source of a typed class that will work
with the spec of a given Table object. if nothing else, users can use this to more easily have typed classes generated from table classes (with scheme definitions).

e.g
var CustomerTable = new Table(new Stringfield("Name"), new IntField("Age"));
var TypedCustSrc = CustomerTable.GetTypedSrc();
//
//  insert some t4 magic or write TypedCustSrc to disk as an include file or whatever
//
var TypedCust  = new TypedCustomerTable(); //which was defined in TypedCustSrc

The tricky part is the insert some t4 magic stuff - haven't seen C# use T4 for this purpose, but I haven't looked very hard, I must admit

Usually, a customer would want to use TypedCust in a larger setting, and he might want to add more methods to the class, subclass it and perhaps add interfaces to it
I have no idea how that should be done. This is why I think perhaps the annotated approach is smarter  -that we give support for tightdb Table objects to read/write
fields from annotated user objects of any type.  e.g.  Table.Store(Object O)

so the user would have :

[TightdbTableFile("c:\data\customer.tightdb")]
class ExistingCustomer : BaseCustomer , IWhateverable ,IComparable ,IEnumerable<Invoices>
{
    public list<Invoice> Invoices();//not stored in database

	[TightDbField("Name")]
	public String Name;

	public int Counter;  //not stored in database

	[TightDbField("Age")]
	public int Age;

	[TightDbRowNumber]//will be set to the row number in the underlying table
	public long RowNumber;

	//here goes loads of methods
}


and then :

var CustomerTable = new Table("Name".Stringfield(), "Age".IntFiled());

var MyCustomer = New ExistingCustomer(bla bla);

blablaBuildCustomerInGUI()

CustomerTable.Store(MyCustomer);



We already have (untyped) :

foreach (var row in CustomerTable) 
{
   //work with row e.g. console.Writeline(row.GetString("Name"));
}


we could have :
foreach (var row in CustomerTable)
{
   var myCustomer = new Existingcustomer();
   row.Load(myCustomer);
   myCustomer.DoThis();
   ExistingStuff.doThat(myCustomer as BaseCustomer);
   row.Store(myCustomer);
}

thus, people could work with their existing object hierachies, integrating tightdb only by annotating any fields that should be stored and loaded in the class
Of course this is type safe as long as the customer annotates correctly in his class definition. We will complain at runtime if things doesn't match up


As I see it, we have two conflicting user needs, speed and convenience, and while generated source yields speed, it is not very convenient if You already have
classes that You need to save and store to tightdb, while the annotated method is super easy to apply to existing projects, but load and store will be somewhat slow
as we will need to use inspection to get to the fields. 
However, if the customer have a lot of read/store in a small part of the application, he can go untyped in that part for speed, and stay with the easy-to-use approach
in the rest of his app.